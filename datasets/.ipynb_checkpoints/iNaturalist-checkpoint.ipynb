{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23031a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "653595b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "from typing import List,Dict,Tuple\n",
    "import copy\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import enum\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, CenterCrop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3c6f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class INaturalistSplit(enum.Enum):\n",
    "  #\"\"\"The different split for the iNaturalist dataset.\"\"\"\n",
    "    USER_120K = enum.auto()\n",
    "    GEO_100 = enum.auto()\n",
    "    GEO_300 = enum.auto()\n",
    "    GEO_1K = enum.auto()\n",
    "    GEO_3K = enum.auto()\n",
    "    GEO_10K = enum.auto()\n",
    "    GEO_30K = enum.auto()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<%s.%s>' % (self.__class__.__name__, self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55b8f3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<INaturalistSplit.USER_120K>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INaturalistSplit.USER_120K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21e8da7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<enum 'INaturalistSplit'>\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(INaturalistSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "479b67a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18446/3948676179.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "b=3\n",
    "b.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0713c17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decb6894",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientData(object, metaclass=abc.ABCMeta):\n",
    "    \"\"\"Object to hold a federated dataset.\n",
    "    The federated dataset is represented as a list of client ids, and\n",
    "    a function to look up the local dataset for each client id.\n",
    "    Note: Cross-device federated learning does not use client IDs or perform any\n",
    "    tracking of clients. However in simulation experiments using centralized test\n",
    "    data the experimenter may select specific clients to be processed per round.\n",
    "    The concept of a client ID is only available at the preprocessing stage when\n",
    "    preparing input data for the simulation and is not part of the TensorFlow\n",
    "    Federated core APIs.\n",
    "    Each client's local dataset is represented as a `tf.data.Dataset`, but\n",
    "    generally this class (and the corresponding datasets hosted by TFF) can\n",
    "    easily be consumed by any Python-based ML framework as `numpy` arrays:\n",
    "    ```python\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_federated as tff\n",
    "    import tensorflow_datasets as tfds\n",
    "    for client_id in sampled_client_ids[:5]:\n",
    "    client_local_dataset = tfds.as_numpy(\n",
    "        emnist_train.create_tf_dataset_for_client(client_id))\n",
    "    # client_local_dataset is an iterable of structures of numpy arrays\n",
    "    for example in client_local_dataset:\n",
    "      print(example)\n",
    "    ```\n",
    "    If desiring a manner for constructing ClientData objects for testing purposes,\n",
    "    please see the `tff.simulation.datasets.TestClientData` class, as it provides\n",
    "    an easy way to construct toy federated datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    @abc.abstractproperty\n",
    "    def client_ids(self) -> List[str]:\n",
    "        \"\"\"A list of string identifiers for clients in this dataset.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractproperty\n",
    "    def serializable_dataset_fn(self):\n",
    "        \"\"\"A callable accepting a client ID and returning a `tf.data.Dataset`.\n",
    "        Note that this callable must be traceable by TF, as it will be used in the\n",
    "        context of a `tf.function`.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def create_tf_dataset_for_client(self, client_id: str) -> tf.data.Dataset:\n",
    "        \"\"\"Creates a new `tf.data.Dataset` containing the client training examples.\n",
    "        This function will create a dataset for a given client, given that\n",
    "        `client_id` is contained in the `client_ids` property of the `ClientData`.\n",
    "        Unlike `create_dataset`, this method need not be serializable.\n",
    "        Args:\n",
    "          client_id: The string client_id for the desired client.\n",
    "        Returns:\n",
    "          A `tf.data.Dataset` object.\n",
    "        \"\"\"\n",
    "        if client_id not in self.client_ids:\n",
    "            raise ValueError(\n",
    "              'ID [{i}] is not a client in this ClientData. See '\n",
    "              'property `client_ids` for the list of valid ids.'.format(\n",
    "                  i=client_id))\n",
    "        return self.serializable_dataset_fn(client_id)\n",
    "\n",
    "    @property\n",
    "    def dataset_computation(self):\n",
    "        \"\"\"A `tff.Computation` accepting a client ID, returning a dataset.\n",
    "        Note: the `dataset_computation` property is intended as a TFF-specific\n",
    "        performance optimization for distributed execution.\n",
    "        \"\"\"\n",
    "        if (not hasattr(self, '_cached_dataset_computation')) or (\n",
    "            self._cached_dataset_computation is None):\n",
    "\n",
    "            @computations.tf_computation(tf.string)\n",
    "            def dataset_computation(client_id):\n",
    "                return self.serializable_dataset_fn(client_id)\n",
    "\n",
    "            self._cached_dataset_computation = dataset_computation\n",
    "        return self._cached_dataset_computation\n",
    "\n",
    "    @abc.abstractproperty\n",
    "    def element_type_structure(self):\n",
    "    \"\"\"The element type information of the client datasets.\n",
    "    Returns:\n",
    "      A nested structure of `tf.TensorSpec` objects defining the type of the\n",
    "    elements returned by datasets in this `ClientData` object.\n",
    "    \"\"\"\n",
    "        pass\n",
    "\n",
    "    def datasets(\n",
    "      self,\n",
    "      limit_count: Optional[int] = None,\n",
    "      seed: Optional[Union[int, Sequence[int]]] = None\n",
    "    ) -> Iterable[tf.data.Dataset]:\n",
    "    \"\"\"Yields the `tf.data.Dataset` for each client in random order.\n",
    "    This function is intended for use building a static array of client data\n",
    "    to be provided to the top-level federated computation.\n",
    "    Args:\n",
    "      limit_count: Optional, a maximum number of datasets to return.\n",
    "      seed: Optional, a seed to determine the order in which clients are\n",
    "        processed in the joined dataset. The seed can be any nonnegative 32-bit\n",
    "        integer, an array of such integers, or `None`.\n",
    "    \"\"\"\n",
    "    check_numpy_random_seed(seed)\n",
    "    # Create a copy to prevent the original list being reordered\n",
    "    client_ids = self.client_ids.copy()\n",
    "    np.random.RandomState(seed=seed).shuffle(client_ids)\n",
    "    count = 0\n",
    "    for client_id in client_ids:\n",
    "        if limit_count is not None and count >= limit_count:\n",
    "        return\n",
    "        count += 1\n",
    "        dataset = self.create_tf_dataset_for_client(client_id)\n",
    "        py_typecheck.check_type(dataset, tf.data.Dataset)\n",
    "        yield dataset\n",
    "\n",
    "    def create_tf_dataset_from_all_clients(\n",
    "      self,\n",
    "      seed: Optional[Union[int, Sequence[int]]] = None) -> tf.data.Dataset:\n",
    "    \"\"\"Creates a new `tf.data.Dataset` containing _all_ client examples.\n",
    "    This function is intended for use training centralized, non-distributed\n",
    "    models (num_clients=1). This can be useful as a point of comparison\n",
    "    against federated models.\n",
    "    Currently, the implementation produces a dataset that contains\n",
    "    all examples from a single client in order, and so generally additional\n",
    "    shuffling should be performed.\n",
    "    Args:\n",
    "      seed: Optional, a seed to determine the order in which clients are\n",
    "        processed in the joined dataset. The seed can be any nonnegative 32-bit\n",
    "        integer, an array of such integers, or `None`.\n",
    "    Returns:\n",
    "      A `tf.data.Dataset` object.\n",
    "    \"\"\"\n",
    "    check_numpy_random_seed(seed)\n",
    "    client_ids = self.client_ids.copy()\n",
    "    np.random.RandomState(seed=seed).shuffle(client_ids)\n",
    "    nested_dataset = tf.data.Dataset.from_tensor_slices(client_ids)\n",
    "    # We apply serializable_dataset_fn here to avoid loading all client datasets\n",
    "    # in memory, which is slow. Note that tf.data.Dataset.map implicitly wraps\n",
    "    # the input mapping in a tf.function.\n",
    "    example_dataset = nested_dataset.flat_map(self.serializable_dataset_fn)\n",
    "    return example_dataset\n",
    "\n",
    "  def preprocess(\n",
    "      self, preprocess_fn: Callable[[tf.data.Dataset],\n",
    "                                    tf.data.Dataset]) -> 'ClientData':\n",
    "    \"\"\"Applies `preprocess_fn` to each client's data.\n",
    "    Args:\n",
    "      preprocess_fn: A callable accepting a `tf.data.Dataset` and returning a\n",
    "        preprocessed `tf.data.Dataset`. This function must be traceable by TF.\n",
    "    Returns:\n",
    "      A `tff.simulation.datasets.ClientData`.\n",
    "    Raises:\n",
    "      IncompatiblePreprocessFnError: If `preprocess_fn` is a `tff.Computation`.\n",
    "    \"\"\"\n",
    "    py_typecheck.check_callable(preprocess_fn)\n",
    "    if isinstance(preprocess_fn, computation_base.Computation):\n",
    "      raise IncompatiblePreprocessFnError()\n",
    "    return PreprocessClientData(self, preprocess_fn)\n",
    "\n",
    "  @classmethod\n",
    "  def from_clients_and_tf_fn(\n",
    "      cls,\n",
    "      client_ids: Iterable[str],\n",
    "      serializable_dataset_fn: Callable[[str], tf.data.Dataset],\n",
    "  ) -> 'ClientData':\n",
    "    \"\"\"Constructs a `ClientData` based on the given function.\n",
    "    Args:\n",
    "      client_ids: A non-empty list of strings to use as input to\n",
    "        `create_dataset_fn`.\n",
    "      serializable_dataset_fn: A function that takes a client_id from the above\n",
    "        list, and returns a `tf.data.Dataset`. This function must be\n",
    "        serializable and usable within the context of a `tf.function` and\n",
    "        `tff.Computation`.\n",
    "    Returns:\n",
    "      A `ClientData` object.\n",
    "    \"\"\"\n",
    "    return ConcreteClientData(client_ids, serializable_dataset_fn)\n",
    "\n",
    "  @classmethod\n",
    "  def train_test_client_split(\n",
    "      cls,\n",
    "      client_data: 'ClientData',\n",
    "      num_test_clients: int,\n",
    "      seed: Optional[Union[int, Sequence[int]]] = None\n",
    "  ) -> Tuple['ClientData', 'ClientData']:\n",
    "    \"\"\"Returns a pair of (train, test) `ClientData`.\n",
    "    This method partitions the clients of `client_data` into two `ClientData`\n",
    "    objects with disjoint sets of `ClientData.client_ids`. All clients in the\n",
    "    test `ClientData` are guaranteed to have non-empty datasets, but the\n",
    "    training `ClientData` may have clients with no data.\n",
    "    Note: This method may be expensive, and so it may be useful to avoid calling\n",
    "    multiple times and holding on to the results.\n",
    "    Args:\n",
    "      client_data: The base `ClientData` to split.\n",
    "      num_test_clients: How many clients to hold out for testing. This can be at\n",
    "        most len(client_data.client_ids) - 1, since we don't want to produce\n",
    "        empty `ClientData`.\n",
    "      seed: Optional seed to fix shuffling of clients before splitting. The seed\n",
    "        can be any nonnegative 32-bit integer, an array of such integers, or\n",
    "        `None`.\n",
    "    Returns:\n",
    "      A pair (train_client_data, test_client_data), where test_client_data\n",
    "      has `num_test_clients` selected at random, subject to the constraint they\n",
    "      each have at least 1 batch in their dataset.\n",
    "    Raises:\n",
    "      ValueError: If `num_test_clients` cannot be satistifed by `client_data`,\n",
    "        or too many clients have empty datasets.\n",
    "    \"\"\"\n",
    "    if num_test_clients <= 0:\n",
    "      raise ValueError('Please specify num_test_clients > 0.')\n",
    "\n",
    "    if len(client_data.client_ids) <= num_test_clients:\n",
    "      raise ValueError('The client_data supplied has only {} clients, but '\n",
    "                       '{} test clients were requested.'.format(\n",
    "                           len(client_data.client_ids), num_test_clients))\n",
    "\n",
    "    check_numpy_random_seed(seed)\n",
    "    train_client_ids = list(client_data.client_ids)\n",
    "    np.random.RandomState(seed).shuffle(train_client_ids)\n",
    "    # These clients will be added back into the training set at the end.\n",
    "    clients_with_insufficient_batches = []\n",
    "    test_client_ids = []\n",
    "    while len(test_client_ids) < num_test_clients:\n",
    "      if not train_client_ids or (\n",
    "          # Arbitrarily threshold where \"many\" (relative to num_test_clients)\n",
    "          # clients have no data. Note: If needed, we could make this limit\n",
    "          # configurable.\n",
    "          len(clients_with_insufficient_batches) > 5 * num_test_clients + 10):\n",
    "\n",
    "        raise ValueError('Encountered too many clients with no data.')\n",
    "\n",
    "      client_id = train_client_ids.pop()\n",
    "      dataset = client_data.create_tf_dataset_for_client(client_id)\n",
    "      try:\n",
    "        _ = next(dataset.__iter__())\n",
    "      except StopIteration:\n",
    "        logging.warning('Client %s had no data, skipping.', client_id)\n",
    "        clients_with_insufficient_batches.append(client_id)\n",
    "        continue\n",
    "\n",
    "      test_client_ids.append(client_id)\n",
    "\n",
    "    # Invariant for successful exit of the above loop:\n",
    "    assert len(test_client_ids) == num_test_clients\n",
    "\n",
    "    def from_ids(client_ids: Iterable[str]) -> 'ClientData':\n",
    "      return cls.from_clients_and_tf_fn(client_ids,\n",
    "                                        client_data.serializable_dataset_fn)\n",
    "\n",
    "    return (from_ids(train_client_ids + clients_with_insufficient_batches),\n",
    "            from_ids(test_client_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38f576d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(\n",
    "    image_dir: str = 'images',\n",
    "    cache_dir: str = 'cache',\n",
    "    split: INaturalistSplit = INaturalistSplit.USER_120K):\n",
    "    #-> Tuple[ClientData, tf.data.Dataset]:#\n",
    "    \"\"\"Loads a federated version of the iNaturalist 2017 dataset.\n",
    "    If the dataset is loaded for the first time, the images for the entire\n",
    "    iNaturalist 2017 dataset will be downloaded from AWS Open Data Program.\n",
    "    The dataset is created from the images stored inside the image_dir. Once the\n",
    "    dataset is created, it will be cached inside the cache directory.\n",
    "    The `tf.data.Datasets` returned by\n",
    "    `tff.simulation.datasets.ClientData.create_tf_dataset_for_client` will yield\n",
    "    `collections.OrderedDict` objects at each iteration, with the following keys\n",
    "    and values:\n",
    "    -   `'image/decoded'`: A `tf.Tensor` with `dtype=tf.uint8` that\n",
    "        corresponds to the pixels of the images.\n",
    "    -   `'class'`: A `tf.Tensor` with `dtype=tf.int64` and shape [1],\n",
    "        corresponding to the class label.\n",
    "    Seven splits of iNaturalist datasets are available. The details of each\n",
    "    different dataset split can be found in https://arxiv.org/abs/2003.08082.\n",
    "    For the USER_120K dataset, the images are split by the user id.\n",
    "    The number of clients for USER_120K is 9275. The training set contains 120.300\n",
    "    images of 1203 species, and test set contains 35641 images.\n",
    "    For the GEO_* datasets, the images are splitted by the geo location.\n",
    "    The number of clients for the GEO_* datasets:\n",
    "    1. GEO_100: 3607.\n",
    "    2. GEO_300: 1209.\n",
    "    3. GEO_1K: 369.\n",
    "    4: GEO_3K: 136.\n",
    "    5. GEO_10K: 39.\n",
    "    6. GEO_30K: 12.\n",
    "    Args:\n",
    "    image_dir: (Optional) The directory containing the images downloaded from\n",
    "              https://github.com/visipedia/inat_comp/tree/master/2017\n",
    "    cache_dir: (Optional) The directory to cache the created datasets.\n",
    "    split: (Optional) The split of the dataset, default to be split by users.\n",
    "    Returns:\n",
    "    Tuple of (train, test) where the tuple elements are\n",
    "    a `tff.simulation.datasets.ClientData` and a  `tf.data.Dataset`.\n",
    "    \"\"\"\n",
    "    logging.basicConfig(filename='load_data.log', level=logging.INFO)\n",
    "    logger = logging.getLogger(LOGGER)\n",
    "    logger.info('Start to load data.')\n",
    "    if not os.path.exists(cache_dir):\n",
    "        logger.info('Creating cache directory.')\n",
    "        os.mkdir(cache_dir)\n",
    "    try:\n",
    "        return _load_data_from_cache(cache_dir, split)\n",
    "    except Exception:  # pylint: disable=broad-except:\n",
    "        if not image_dir:\n",
    "            raise ValueError('image_dir cannot be empty or none.')\n",
    "        if not os.path.isdir(image_dir):\n",
    "            logger.error('Image directory %s does not exist', image_dir)\n",
    "            raise ValueError('%s does not exist or is not a directory' % image_dir)\n",
    "    logger.info('Start to download the images for the training set.')\n",
    "    tf.keras.utils.get_file(\n",
    "        'train_val_images.tar.gz',\n",
    "        origin=INAT_TRAIN_IMAGE_URL,\n",
    "        file_hash=INAT_TRAIN_IMAGE_MD5_CHECKSUM,\n",
    "        hash_algorithm='md5',\n",
    "        extract=True,\n",
    "        cache_dir=image_dir)\n",
    "    logger.info('Finish to download the images for the training set.')\n",
    "    logger.info('Start to download the images for the testing set.')\n",
    "    tf.keras.utils.get_file(\n",
    "        'test2017.tar.gz',\n",
    "        origin=INAT_TEST_IMAGE_URL,\n",
    "        file_hash=INAT_TEST_IMAGE_MD5_CHECKSUM,\n",
    "        hash_algorithm='md5',\n",
    "        extract=True,\n",
    "        cache_dir=image_dir)\n",
    "    logger.info('Finish to download the images for the testing set.')\n",
    "    return _generate_data_from_image_dir(image_dir, cache_dir, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29073f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c69b4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ae1785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea87115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819c6653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c38c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a017fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b32d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_train_data_files(image_path_map: Dict[str, str], cache_dir: str,\n",
    "                             split: INaturalistSplit, train_path: str):\n",
    "    \n",
    "    '''\n",
    "    Create the train data and persist it into a separate file per user.\n",
    "    Args:\n",
    "    image_path_map: The dictionary containing the image id to image path\n",
    "      mapping.\n",
    "    cache_dir: The directory containing the created datasets.\n",
    "    split: The split of the federated iNaturalist 2017 dataset.\n",
    "    train_path: The path to the mapping file for training data.\n",
    "    '''\n",
    "    logger = logging.getLogger(LOGGER)\n",
    "\n",
    "    mapping_table = utils.read_csv(train_path)\n",
    "    user_id_col = split.name.lower()\n",
    "    expected_cols = [user_id_col, 'image_id', 'class']\n",
    "    if not all(col in mapping_table[0].keys() for col in expected_cols):\n",
    "        logger.error('%s has wrong format.', train_path)\n",
    "        raise ValueError(\n",
    "            'The mapping file must contain the user_id for the chosen split, image_id and class columns. '\n",
    "            'The existing columns are %s' % ','.join(mapping_table[0].keys()))\n",
    "    cache_dir = os.path.join(cache_dir, split.name.lower(), TRAIN_SUB_DIR)\n",
    "    if not os.path.exists(cache_dir):\n",
    "        logger.info('Creating cache directory for training data.')\n",
    "        os.makedirs(cache_dir)\n",
    "    mapping_per_user = collections.defaultdict(list)\n",
    "    for row in mapping_table:\n",
    "        user_id = row[user_id_col]\n",
    "        if user_id != 'NA':\n",
    "            mapping_per_user[user_id].append(row)\n",
    "    for user_id, data in mapping_per_user.items():\n",
    "        examples = _create_dataset_with_mapping(image_path_map, data)\n",
    "    with tf.io.TFRecordWriter(os.path.join(cache_dir, str(user_id))) as writer:\n",
    "        for example in examples:\n",
    "            writer.write(example.SerializeToString())\n",
    "        logger.info('Created tfrecord file for user %s with %d examples, at %s',\n",
    "                  user_id, len(examples), cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5e891c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2114374364.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_18446/2114374364.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    split, train_path: str)\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def _create_train_data_files(image_path_map = \"/MD1400/jinkyu/train_val_images\", cache_dir: str,\n",
    "                             split, train_path: str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d95edd0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18446/2859023088.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "51468871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Tuple\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision.datasets.utils import download_and_extract_archive, verify_str_arg\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "\n",
    "CATEGORIES_2021 = [\"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\"]\n",
    "\n",
    "DATASET_URLS = {\n",
    "    \"2017\": \"https://ml-inat-competition-datasets.s3.amazonaws.com/2017/train_val_images.tar.gz\",\n",
    "    \"2018\": \"https://ml-inat-competition-datasets.s3.amazonaws.com/2018/train_val2018.tar.gz\",\n",
    "    \"2019\": \"https://ml-inat-competition-datasets.s3.amazonaws.com/2019/train_val2019.tar.gz\",\n",
    "    \"2021_train\": \"https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train.tar.gz\",\n",
    "    \"2021_train_mini\": \"https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train_mini.tar.gz\",\n",
    "    \"2021_valid\": \"https://ml-inat-competition-datasets.s3.amazonaws.com/2021/val.tar.gz\",\n",
    "}\n",
    "\n",
    "DATASET_MD5 = {\n",
    "    \"2017\": \"7c784ea5e424efaec655bd392f87301f\",\n",
    "    \"2018\": \"b1c6952ce38f31868cc50ea72d066cc3\",\n",
    "    \"2019\": \"c60a6e2962c9b8ccbd458d12c8582644\",\n",
    "    \"2021_train\": \"38a7bb733f7a09214d44293460ec0021\",\n",
    "    \"2021_train_mini\": \"db6ed8330e634445efc8fec83ae81442\",\n",
    "    \"2021_valid\": \"f6f6e0e242e3d4c9569ba56400938afc\",\n",
    "}\n",
    "\n",
    "\n",
    "class INaturalist(VisionDataset):\n",
    "    \"\"\"`iNaturalist <https://github.com/visipedia/inat_comp>`_ Dataset.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where the image files are stored.\n",
    "            This class does not require/use annotation files.\n",
    "        version (string, optional): Which version of the dataset to download/use. One of\n",
    "            '2017', '2018', '2019', '2021_train', '2021_train_mini', '2021_valid'.\n",
    "            Default: `2021_train`.\n",
    "        target_type (string or list, optional): Type of target to use, for 2021 versions, one of:\n",
    "\n",
    "            - ``full``: the full category (species)\n",
    "            - ``kingdom``: e.g. \"Animalia\"\n",
    "            - ``phylum``: e.g. \"Arthropoda\"\n",
    "            - ``class``: e.g. \"Insecta\"\n",
    "            - ``order``: e.g. \"Coleoptera\"\n",
    "            - ``family``: e.g. \"Cleridae\"\n",
    "            - ``genus``: e.g. \"Trichodes\"\n",
    "\n",
    "            for 2017-2019 versions, one of:\n",
    "\n",
    "            - ``full``: the full (numeric) category\n",
    "            - ``super``: the super category, e.g. \"Amphibians\"\n",
    "\n",
    "            Can also be a list to output a tuple with all specified target types.\n",
    "            Defaults to ``full``.\n",
    "        transform (callable, optional): A function/transform that takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        version: str = \"2021_train\",\n",
    "        target_type: Union[List[str], str] = \"full\",\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "        download: bool = False,\n",
    "    ) -> None:\n",
    "        self.version = verify_str_arg(version, \"version\", DATASET_URLS.keys())\n",
    "\n",
    "        super().__init__(os.path.join(root, version), transform=transform, target_transform=target_transform)\n",
    "\n",
    "        os.makedirs(root, exist_ok=True)\n",
    "        if download:\n",
    "            self.download()\n",
    "        print(\"self.root\",self.root)\n",
    "        print(self._check_integrity())\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError(\"Dataset not found or corrupted. You can use download=True to download it\")\n",
    "\n",
    "        self.all_categories: List[str] = []\n",
    "\n",
    "        # map: category type -> name of category -> index\n",
    "        self.categories_index: Dict[str, Dict[str, int]] = {}\n",
    "\n",
    "        # list indexed by category id, containing mapping from category type -> index\n",
    "        self.categories_map: List[Dict[str, int]] = []\n",
    "\n",
    "        if not isinstance(target_type, list):\n",
    "            target_type = [target_type]\n",
    "        if self.version[:4] == \"2021\":\n",
    "            self.target_type = [verify_str_arg(t, \"target_type\", (\"full\", *CATEGORIES_2021)) for t in target_type]\n",
    "            self._init_2021()\n",
    "        else:\n",
    "            self.target_type = [verify_str_arg(t, \"target_type\", (\"full\", \"super\")) for t in target_type]\n",
    "            self._init_pre2021()\n",
    "\n",
    "        # index of all files: (full category id, filename)\n",
    "        self.index: List[Tuple[int, str]] = []\n",
    "\n",
    "        for dir_index, dir_name in enumerate(self.all_categories):\n",
    "            files = os.listdir(os.path.join(self.root, dir_name))\n",
    "            for fname in files:\n",
    "                self.index.append((dir_index, fname))\n",
    "\n",
    "    def _init_2021(self) -> None:\n",
    "        \"\"\"Initialize based on 2021 layout\"\"\"\n",
    "\n",
    "        self.all_categories = sorted(os.listdir(self.root))\n",
    "\n",
    "        # map: category type -> name of category -> index\n",
    "        self.categories_index = {k: {} for k in CATEGORIES_2021}\n",
    "\n",
    "        for dir_index, dir_name in enumerate(self.all_categories):\n",
    "            pieces = dir_name.split(\"_\")\n",
    "            if len(pieces) != 8:\n",
    "                raise RuntimeError(f\"Unexpected category name {dir_name}, wrong number of pieces\")\n",
    "            if pieces[0] != f\"{dir_index:05d}\":\n",
    "                raise RuntimeError(f\"Unexpected category id {pieces[0]}, expecting {dir_index:05d}\")\n",
    "            cat_map = {}\n",
    "            for cat, name in zip(CATEGORIES_2021, pieces[1:7]):\n",
    "                if name in self.categories_index[cat]:\n",
    "                    cat_id = self.categories_index[cat][name]\n",
    "                else:\n",
    "                    cat_id = len(self.categories_index[cat])\n",
    "                    self.categories_index[cat][name] = cat_id\n",
    "                cat_map[cat] = cat_id\n",
    "            self.categories_map.append(cat_map)\n",
    "\n",
    "    def _init_pre2021(self) -> None:\n",
    "        \"\"\"Initialize based on 2017-2019 layout\"\"\"\n",
    "\n",
    "        # map: category type -> name of category -> index\n",
    "        self.categories_index = {\"super\": {}}\n",
    "\n",
    "        cat_index = 0\n",
    "        super_categories = sorted(os.listdir(self.root))\n",
    "        for sindex, scat in enumerate(super_categories):\n",
    "            self.categories_index[\"super\"][scat] = sindex\n",
    "            subcategories = sorted(os.listdir(os.path.join(self.root, scat)))\n",
    "            for subcat in subcategories:\n",
    "                if self.version == \"2017\":\n",
    "                    # this version does not use ids as directory names\n",
    "                    subcat_i = cat_index\n",
    "                    cat_index += 1\n",
    "                else:\n",
    "                    try:\n",
    "                        subcat_i = int(subcat)\n",
    "                    except ValueError:\n",
    "                        raise RuntimeError(f\"Unexpected non-numeric dir name: {subcat}\")\n",
    "                if subcat_i >= len(self.categories_map):\n",
    "                    old_len = len(self.categories_map)\n",
    "                    self.categories_map.extend([{}] * (subcat_i - old_len + 1))\n",
    "                    self.all_categories.extend([\"\"] * (subcat_i - old_len + 1))\n",
    "                if self.categories_map[subcat_i]:\n",
    "                    raise RuntimeError(f\"Duplicate category {subcat}\")\n",
    "                self.categories_map[subcat_i] = {\"super\": sindex}\n",
    "                self.all_categories[subcat_i] = os.path.join(scat, subcat)\n",
    "\n",
    "        # validate the dictionary\n",
    "        for cindex, c in enumerate(self.categories_map):\n",
    "            if not c:\n",
    "                raise RuntimeError(f\"Missing category {cindex}\")\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where the type of target specified by target_type.\n",
    "        \"\"\"\n",
    "\n",
    "        cat_id, fname = self.index[index]\n",
    "        img = Image.open(os.path.join(self.root, self.all_categories[cat_id], fname))\n",
    "        print(\"fname\",fname)\n",
    "        target: Any = []\n",
    "        for t in self.target_type:\n",
    "            if t == \"full\":\n",
    "                target.append(cat_id)\n",
    "            else:\n",
    "                target.append(self.categories_map[cat_id][t])\n",
    "        target = tuple(target) if len(target) > 1 else target[0]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.index)\n",
    "\n",
    "    def category_name(self, category_type: str, category_id: int) -> str:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            category_type(str): one of \"full\", \"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\" or \"super\"\n",
    "            category_id(int): an index (class id) from this category\n",
    "\n",
    "        Returns:\n",
    "            the name of the category\n",
    "        \"\"\"\n",
    "        if category_type == \"full\":\n",
    "            return self.all_categories[category_id]\n",
    "        else:\n",
    "            if category_type not in self.categories_index:\n",
    "                raise ValueError(f\"Invalid category type '{category_type}'\")\n",
    "            else:\n",
    "                for name, id in self.categories_index[category_type].items():\n",
    "                    if id == category_id:\n",
    "                        return name\n",
    "                raise ValueError(f\"Invalid category id {category_id} for {category_type}\")\n",
    "\n",
    "\n",
    "    def _check_integrity(self) -> bool:\n",
    "        return os.path.exists(self.root) and len(os.listdir(self.root)) > 0\n",
    "\n",
    "    def download(self) -> None:\n",
    "        if self._check_integrity():\n",
    "            raise RuntimeError(\n",
    "                f\"The directory {self.root} already exists. \"\n",
    "                f\"If you want to re-download or re-extract the images, delete the directory.\"\n",
    "            )\n",
    "\n",
    "        base_root = os.path.dirname(self.root)\n",
    "\n",
    "        download_and_extract_archive(\n",
    "            DATASET_URLS[self.version], base_root, filename=f\"{self.version}.tgz\", md5=DATASET_MD5[self.version]\n",
    "        )\n",
    "\n",
    "        orig_dir_name = os.path.join(base_root, os.path.basename(DATASET_URLS[self.version]).rstrip(\".tar.gz\"))\n",
    "        if not os.path.exists(orig_dir_name):\n",
    "            raise RuntimeError(f\"Unable to find downloaded files at {orig_dir_name}\")\n",
    "        os.rename(orig_dir_name, self.root)\n",
    "        print(f\"Dataset version '{self.version}' has been downloaded and prepared for use\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "60dd2e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "08da94f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.root /MD1400/jinkyu/train_val_images/2017\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "trainset = INaturalist(root = '/MD1400/jinkyu/train_val_images',version = '2017', download = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "86a291c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('/MD1400/jinkyu/train_val_images') and len(os.listdir('/MD1400/jinkyu/train_val_images'))>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "672adbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('/MD1400/jinkyu/train_val_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1dd2c128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(trainset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "773bb4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "675170"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "96d48a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '38a37064e7ba2cba7e24c7abfcee9702.jpg')\n"
     ]
    }
   ],
   "source": [
    "print(trainset.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c2fcac70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Actinopterygii/Abudefduf saxatilis'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.all_categories[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7d245e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=800x518 at 0x7F073C425C10>, 0)\n"
     ]
    }
   ],
   "source": [
    "print(trainset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c194ded8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5089\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset.all_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4a1ae26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aves/Rhipidura fuliginosa\n"
     ]
    }
   ],
   "source": [
    "print(trainset.all_categories[1054])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b7492e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fname aeed4898f1d933ec73f36558c3bf49c0.jpg\n",
      "(<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=800x528 at 0x7F0745744550>, 393)\n"
     ]
    }
   ],
   "source": [
    "print(trainset[60132])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "80fcfe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_image_map(image_dir: str) -> Dict[str, str]:\n",
    "    \"\"\"Create an dictionary with key as image id, value as path to the image file.\n",
    "    Args:\n",
    "    image_dir: The directory containing all the images.\n",
    "    Returns:\n",
    "    The dictionary containing the image id to image file path mapping.\n",
    "    \"\"\"\n",
    "    image_map = {}\n",
    "    for root, _, files in os.walk(image_dir):\n",
    "        for f in files:\n",
    "            if f.endswith('.jpg'):\n",
    "                image_id = f.rstrip('.jpg')\n",
    "                image_path = os.path.join(root, f)\n",
    "                image_map[image_id] = image_path\n",
    "    return image_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "45df8351",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_map = _generate_image_map('/MD1400/jinkyu/train_val_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2c9374dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/MD1400/jinkyu/train_val_images/2017/Plantae/Nymphaea odorata/b6f3b1c50816b4eab7e4dfb693a669d2.jpg'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_map['b6f3b1c50816b4eab7e4dfb693a669d2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123f4e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3a495518",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./iNaturalist_client.json\"\n",
    "with open(file_path,'r') as f:\n",
    "    client_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fd5e4955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Adam_Heathcote',\n",
       " {'client_idx': 1,\n",
       "  'client_data': [{'image_id': 'c2cfd0484188da465b09e0ff962de74d',\n",
       "    'class': '1001',\n",
       "    'label': '9346'},\n",
       "   {'image_id': '7db1ea38b4d361fcaf37a477acc80cfb',\n",
       "    'class': '1110',\n",
       "    'label': '57458'},\n",
       "   {'image_id': '1adc627e90a6ed9349074c0bc528d6b7',\n",
       "    'class': '1041',\n",
       "    'label': '6433'},\n",
       "   {'image_id': 'fdef4f285a898ccc73618d6c76f872a5',\n",
       "    'class': '982',\n",
       "    'label': '118078'},\n",
       "   {'image_id': 'da4771d82e809c84280ac77e68d8c824',\n",
       "    'class': '1110',\n",
       "    'label': '57458'},\n",
       "   {'image_id': '2c984f32cfd3572539e013a01482be43',\n",
       "    'class': '1087',\n",
       "    'label': '84549'},\n",
       "   {'image_id': '05ee245c5c20fb44ebca20552d1579db',\n",
       "    'class': '832',\n",
       "    'label': '12727'},\n",
       "   {'image_id': '5e9fd154e020e2cc3178961d753a2ebe',\n",
       "    'class': '1024',\n",
       "    'label': '52821'},\n",
       "   {'image_id': '2cbef67f8963c2871fae18c411230752',\n",
       "    'class': '207',\n",
       "    'label': '9424'},\n",
       "   {'image_id': 'de01b7fd20dfe9ae5e4e9129aca96867',\n",
       "    'class': '957',\n",
       "    'label': '473'},\n",
       "   {'image_id': '16562ea7640c4d27738281895541ee6d',\n",
       "    'class': '995',\n",
       "    'label': '59029'},\n",
       "   {'image_id': 'fe46d09959bd3ed65599a07c53d68fe3',\n",
       "    'class': '982',\n",
       "    'label': '118078'},\n",
       "   {'image_id': '0e7a56db9169ec350049b2e6da32c571',\n",
       "    'class': '1107',\n",
       "    'label': '4265'},\n",
       "   {'image_id': '6c2722ce524f6649e680bae9aedb1ed7',\n",
       "    'class': '1001',\n",
       "    'label': '9346'},\n",
       "   {'image_id': '28fdbc2210d9f9dfdd88b61ca0463369',\n",
       "    'class': '559',\n",
       "    'label': '48473'},\n",
       "   {'image_id': 'be740386757457626879952f2d776d97',\n",
       "    'class': '1000',\n",
       "    'label': '43111'},\n",
       "   {'image_id': '40c1b5fdc324a64ba581c0578e83b966',\n",
       "    'class': '493',\n",
       "    'label': '14995'},\n",
       "   {'image_id': 'e0d4beeac7d34c5fd5963f26c5542132',\n",
       "    'class': '575',\n",
       "    'label': '41663'},\n",
       "   {'image_id': '378b2c668aa2579e01a72242c0aa3602',\n",
       "    'class': '903',\n",
       "    'label': '127186'},\n",
       "   {'image_id': '0614467a7641249b7945d8ca7617b979',\n",
       "    'class': '332',\n",
       "    'label': '145310'},\n",
       "   {'image_id': '2407ca0794d5b624b6f51cd6cb261c0f',\n",
       "    'class': '614',\n",
       "    'label': '42223'},\n",
       "   {'image_id': 'cf1066fdef792b0beef9cf884a79cee6',\n",
       "    'class': '552',\n",
       "    'label': '44026'},\n",
       "   {'image_id': '767b702c4e61a643d6168167e1993b04',\n",
       "    'class': '1058',\n",
       "    'label': '9721'},\n",
       "   {'image_id': '2e9f160532c935c25cf84fb3e89eef41',\n",
       "    'class': '559',\n",
       "    'label': '48473'},\n",
       "   {'image_id': 'ccb2a8da5d2a9beffe673f90b60e1629',\n",
       "    'class': '575',\n",
       "    'label': '41663'},\n",
       "   {'image_id': '11a2186bc7b787836d12f257841b5f06',\n",
       "    'class': '533',\n",
       "    'label': '39771'},\n",
       "   {'image_id': '43393142ee5d927288c553a7b049c799',\n",
       "    'class': '1103',\n",
       "    'label': '51119'},\n",
       "   {'image_id': '119592634e8f7cb21a6f760ba8ff707c',\n",
       "    'class': '533',\n",
       "    'label': '39771'},\n",
       "   {'image_id': '3b43529d44944d0b0c5c90ee5b084708',\n",
       "    'class': '533',\n",
       "    'label': '39771'},\n",
       "   {'image_id': 'dab2a57101909c3c53f1fb0769661b01',\n",
       "    'class': '679',\n",
       "    'label': '9083'}]})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(client_data.items())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "eb39e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./iNaturalist_client_idx.txt\"\n",
    "dataset = {}\n",
    "with open(filepath) as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        dataset = eval(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b1b6ef48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4707,\n",
       " 15026,\n",
       " 16102,\n",
       " 20355,\n",
       " 26947,\n",
       " 31606,\n",
       " 31645,\n",
       " 31719,\n",
       " 35236,\n",
       " 50474,\n",
       " 52116,\n",
       " 53646,\n",
       " 53788,\n",
       " 57782,\n",
       " 58900,\n",
       " 61756,\n",
       " 73053,\n",
       " 75472,\n",
       " 81102,\n",
       " 82197,\n",
       " 82974,\n",
       " 85952,\n",
       " 87984,\n",
       " 97589,\n",
       " 98691,\n",
       " 99735,\n",
       " 101126,\n",
       " 103636,\n",
       " 110651,\n",
       " 116355]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "9ee02262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Tuple\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision.datasets.utils import download_and_extract_archive, verify_str_arg\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "\n",
    "CATEGORIES_2021 = [\"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\"]\n",
    "\n",
    "DATASET_URLS = {\n",
    "    \"2017\": \"https://ml-inat-competition-datasets.s3.amazonaws.com/2017/train_val_images.tar.gz\",\n",
    "    \"2018\": \"https://ml-inat-competition-datasets.s3.amazonaws.com/2018/train_val2018.tar.gz\",\n",
    "    \"2019\": \"https://ml-inat-competition-datasets.s3.amazonaws.com/2019/train_val2019.tar.gz\",\n",
    "    \"2021_train\": \"https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train.tar.gz\",\n",
    "    \"2021_train_mini\": \"https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train_mini.tar.gz\",\n",
    "    \"2021_valid\": \"https://ml-inat-competition-datasets.s3.amazonaws.com/2021/val.tar.gz\",\n",
    "}\n",
    "\n",
    "DATASET_MD5 = {\n",
    "    \"2017\": \"7c784ea5e424efaec655bd392f87301f\",\n",
    "    \"2018\": \"b1c6952ce38f31868cc50ea72d066cc3\",\n",
    "    \"2019\": \"c60a6e2962c9b8ccbd458d12c8582644\",\n",
    "    \"2021_train\": \"38a7bb733f7a09214d44293460ec0021\",\n",
    "    \"2021_train_mini\": \"db6ed8330e634445efc8fec83ae81442\",\n",
    "    \"2021_valid\": \"f6f6e0e242e3d4c9569ba56400938afc\",\n",
    "}\n",
    "\n",
    "\n",
    "class INaturalist(VisionDataset):\n",
    "    \"\"\"`iNaturalist <https://github.com/visipedia/inat_comp>`_ Dataset.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where the image files are stored.\n",
    "            This class does not require/use annotation files.\n",
    "        version (string, optional): Which version of the dataset to download/use. One of\n",
    "            '2017', '2018', '2019', '2021_train', '2021_train_mini', '2021_valid'.\n",
    "            Default: `2021_train`.\n",
    "        target_type (string or list, optional): Type of target to use, for 2021 versions, one of:\n",
    "\n",
    "            - ``full``: the full category (species)\n",
    "            - ``kingdom``: e.g. \"Animalia\"\n",
    "            - ``phylum``: e.g. \"Arthropoda\"\n",
    "            - ``class``: e.g. \"Insecta\"\n",
    "            - ``order``: e.g. \"Coleoptera\"\n",
    "            - ``family``: e.g. \"Cleridae\"\n",
    "            - ``genus``: e.g. \"Trichodes\"\n",
    "\n",
    "            for 2017-2019 versions, one of:\n",
    "\n",
    "            - ``full``: the full (numeric) category\n",
    "            - ``super``: the super category, e.g. \"Amphibians\"\n",
    "\n",
    "            Can also be a list to output a tuple with all specified target types.\n",
    "            Defaults to ``full``.\n",
    "        transform (callable, optional): A function/transform that takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        csv_path: str,\n",
    "        version: str = \"2021_train\",\n",
    "        target_type: Union[List[str], str] = \"full\",\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "        download: bool = False,\n",
    "        \n",
    "    ) -> None:\n",
    "        self.version = verify_str_arg(version, \"version\", DATASET_URLS.keys())\n",
    "\n",
    "        super().__init__(os.path.join(root, version), transform=transform, target_transform=target_transform)\n",
    "\n",
    "        os.makedirs(root, exist_ok=True)\n",
    "        if download:\n",
    "            self.download()\n",
    "        #print(self.root)\n",
    "        #print(self._check_integrity())\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError(\"Dataset not found or corrupted. You can use download=True to download it\")\n",
    "            \n",
    "          \n",
    "\n",
    "        '''\n",
    "        self.all_categories: List[str] = []\n",
    "\n",
    "        # map: category type -> name of category -> index\n",
    "        self.categories_index: Dict[str, Dict[str, int]] = {}\n",
    "\n",
    "        # list indexed by category id, containing mapping from category type -> index\n",
    "        self.categories_map: List[Dict[str, int]] = []\n",
    "\n",
    "        if not isinstance(target_type, list):\n",
    "            target_type = [target_type]\n",
    "        if self.version[:4] == \"2021\":\n",
    "            self.target_type = [verify_str_arg(t, \"target_type\", (\"full\", *CATEGORIES_2021)) for t in target_type]\n",
    "            self._init_2021()\n",
    "        else:\n",
    "            self.target_type = [verify_str_arg(t, \"target_type\", (\"full\", \"super\")) for t in target_type]\n",
    "            self._init_pre2021()\n",
    "\n",
    "        # index of all files: (full category id, filename)\n",
    "        self.index: List[Tuple[int, str]] = []\n",
    "\n",
    "        for dir_index, dir_name in enumerate(self.all_categories):\n",
    "            files = os.listdir(os.path.join(self.root, dir_name))\n",
    "            for fname in files:\n",
    "                self.index.append((dir_index, fname))\n",
    "        '''\n",
    "        self.image_map = self._generate_image_map(self.root)\n",
    "        self.split_csv = self.read_csv(csv_path)\n",
    "        #self.client_data = _read_client_data(client_data_path)\n",
    "        \n",
    "    def _generate_image_map(self,image_dir: str) -> Dict[str, str]:\n",
    "        \"\"\"Create an dictionary with key as image id, value as path to the image file.\n",
    "        Args:\n",
    "        image_dir: The directory containing all the images.\n",
    "        Returns:\n",
    "        The dictionary containing the image id to image file path mapping.\n",
    "        \"\"\"\n",
    "        image_map = {}\n",
    "        for root, _, files in os.walk(image_dir):\n",
    "            for f in files:\n",
    "                if f.endswith('.jpg'):\n",
    "                    image_id = f.rstrip('.jpg')\n",
    "                    image_path = os.path.join(root, f)\n",
    "                    image_map[image_id] = image_path\n",
    "        return image_map        \n",
    "    '''  \n",
    "    def _read_client_data(file_path: str) -> json:\n",
    "        with open(file_path,'r') as f:\n",
    "            client_data = json.load(f)    \n",
    "        return client_data\n",
    "    '''\n",
    "    def read_csv(self,path: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"Reads a csv file, and returns the content inside a list of dictionaries.\n",
    "        Args:\n",
    "        path: The path to the csv file.\n",
    "        Returns:\n",
    "        A list of dictionaries. Each row in the csv file will be a list entry. The\n",
    "        dictionary is keyed by the column names.\n",
    "        \"\"\"\n",
    "        with open(path, 'r') as f:\n",
    "            return list(csv.DictReader(f))\n",
    "    def _init_2021(self) -> None:\n",
    "        \"\"\"Initialize based on 2021 layout\"\"\"\n",
    "\n",
    "        self.all_categories = sorted(os.listdir(self.root))\n",
    "\n",
    "        # map: category type -> name of category -> index\n",
    "        self.categories_index = {k: {} for k in CATEGORIES_2021}\n",
    "\n",
    "        for dir_index, dir_name in enumerate(self.all_categories):\n",
    "            pieces = dir_name.split(\"_\")\n",
    "            if len(pieces) != 8:\n",
    "                raise RuntimeError(f\"Unexpected category name {dir_name}, wrong number of pieces\")\n",
    "            if pieces[0] != f\"{dir_index:05d}\":\n",
    "                raise RuntimeError(f\"Unexpected category id {pieces[0]}, expecting {dir_index:05d}\")\n",
    "            cat_map = {}\n",
    "            for cat, name in zip(CATEGORIES_2021, pieces[1:7]):\n",
    "                if name in self.categories_index[cat]:\n",
    "                    cat_id = self.categories_index[cat][name]\n",
    "                else:\n",
    "                    cat_id = len(self.categories_index[cat])\n",
    "                    self.categories_index[cat][name] = cat_id\n",
    "                cat_map[cat] = cat_id\n",
    "            self.categories_map.append(cat_map)\n",
    "\n",
    "          \n",
    "            \n",
    "    def _init_pre2021(self) -> None:\n",
    "        \"\"\"Initialize based on 2017-2019 layout\"\"\"\n",
    "\n",
    "        # map: category type -> name of category -> index\n",
    "        self.categories_index = {\"super\": {}}\n",
    "\n",
    "        cat_index = 0\n",
    "        super_categories = sorted(os.listdir(self.root))\n",
    "        for sindex, scat in enumerate(super_categories):\n",
    "            self.categories_index[\"super\"][scat] = sindex\n",
    "            subcategories = sorted(os.listdir(os.path.join(self.root, scat)))\n",
    "            for subcat in subcategories:\n",
    "                if self.version == \"2017\":\n",
    "                    # this version does not use ids as directory names\n",
    "                    subcat_i = cat_index\n",
    "                    cat_index += 1\n",
    "                else:\n",
    "                    try:\n",
    "                        subcat_i = int(subcat)\n",
    "                    except ValueError:\n",
    "                        raise RuntimeError(f\"Unexpected non-numeric dir name: {subcat}\")\n",
    "                if subcat_i >= len(self.categories_map):\n",
    "                    old_len = len(self.categories_map)\n",
    "                    self.categories_map.extend([{}] * (subcat_i - old_len + 1))\n",
    "                    self.all_categories.extend([\"\"] * (subcat_i - old_len + 1))\n",
    "                if self.categories_map[subcat_i]:\n",
    "                    raise RuntimeError(f\"Duplicate category {subcat}\")\n",
    "                self.categories_map[subcat_i] = {\"super\": sindex}\n",
    "                self.all_categories[subcat_i] = os.path.join(scat, subcat)\n",
    "\n",
    "        # validate the dictionary\n",
    "        for cindex, c in enumerate(self.categories_map):\n",
    "            if not c:\n",
    "                raise RuntimeError(f\"Missing category {cindex}\")\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where the type of target specified by target_type.\n",
    "        \"\"\"\n",
    "\n",
    "        this_data = self.split_csv[index]\n",
    "        img = Image.open(self.image_map[this_data['image_id']])\n",
    "        img = img.convert('RGB')\n",
    "        #img = pil_loader(self.image_map[this_data['image_id']])\n",
    "        target = int(this_data['class'])\n",
    "        #print(\"fname\",fname)\n",
    "        '''\n",
    "        target: Any = []\n",
    "\n",
    "        \n",
    "        for t in self.target_type:\n",
    "            if t == \"full\":\n",
    "                target.append(cat_id)\n",
    "            else:\n",
    "                target.append(self.categories_map[cat_id][t])\n",
    "        \n",
    "        target = tuple(target) if len(target) > 1 else target[0]\n",
    "        '''\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.split_csv)\n",
    "\n",
    "    def category_name(self, category_type: str, category_id: int) -> str:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            category_type(str): one of \"full\", \"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\" or \"super\"\n",
    "            category_id(int): an index (class id) from this category\n",
    "\n",
    "        Returns:\n",
    "            the name of the category\n",
    "        \"\"\"\n",
    "        if category_type == \"full\":\n",
    "            return self.all_categories[category_id]\n",
    "        else:\n",
    "            if category_type not in self.categories_index:\n",
    "                raise ValueError(f\"Invalid category type '{category_type}'\")\n",
    "            else:\n",
    "                for name, id in self.categories_index[category_type].items():\n",
    "                    if id == category_id:\n",
    "                        return name\n",
    "                raise ValueError(f\"Invalid category id {category_id} for {category_type}\")\n",
    "\n",
    "\n",
    "    def _check_integrity(self) -> bool:\n",
    "        return os.path.exists(self.root) and len(os.listdir(self.root)) > 0\n",
    "\n",
    "    def download(self) -> None:\n",
    "        if self._check_integrity():\n",
    "            raise RuntimeError(\n",
    "                f\"The directory {self.root} already exists. \"\n",
    "                f\"If you want to re-download or re-extract the images, delete the directory.\"\n",
    "            )\n",
    "\n",
    "        base_root = os.path.dirname(self.root)\n",
    "\n",
    "        download_and_extract_archive(\n",
    "            DATASET_URLS[self.version], base_root, filename=f\"{self.version}.tgz\", md5=DATASET_MD5[self.version]\n",
    "        )\n",
    "\n",
    "        orig_dir_name = os.path.join(base_root, os.path.basename(DATASET_URLS[self.version]).rstrip(\".tar.gz\"))\n",
    "        if not os.path.exists(orig_dir_name):\n",
    "            raise RuntimeError(f\"Unable to find downloaded files at {orig_dir_name}\")\n",
    "        os.rename(orig_dir_name, self.root)\n",
    "        print(f\"Dataset version '{self.version}' has been downloaded and prepared for use\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "94844d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([CenterCrop((224, 224)),\n",
    "                      ToTensor(),\n",
    "                      Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a6fdc51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = INaturalist(root = '/MD1400/jinkyu/train_val_images',csv_path = './inaturalist-user-120k/federated_train_user_120k.csv',version = '2017', download = False, transform = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "14951b26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pil_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18446/469219150.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_18446/2984321389.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mthis_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_csv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m#img = Image.open(self.image_map[this_data['image_id']])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthis_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m#print(\"fname\",fname)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pil_loader' is not defined"
     ]
    }
   ],
   "source": [
    "trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c2ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainset.split_csv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746399b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainset.image_map['e619826038358b817d926d869a0bbcf1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eba32f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(trainset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07154ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in enumerate(dl):\n",
    "    if i<3:\n",
    "        print(\"This is batch \",i)\n",
    "        print(x)\n",
    "        print(len(x[1]))\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "89822d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120300"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset.split_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9d6d7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import  Dataset\n",
    "import torch\n",
    "class DatasetSplit(Dataset):\n",
    "    \"\"\"An abstract Dataset class wrapped around Pytorch Dataset class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = [int(i) for i in idxs]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.idxs[item]]\n",
    "        return torch.tensor(image), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "24afb216",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(DatasetSplit(trainset, dataset[1]), batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "15290517",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=DatasetSplit(trainset, dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "24a0ae68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4707, 15026, 16102, 20355, 26947, 31606, 31645, 31719, 35236, 50474, 52116, 53646, 53788, 57782, 58900, 61756, 73053, 75472, 81102, 82197, 82974, 85952, 87984, 97589, 98691, 99735, 101126, 103636, 110651, 116355]\n"
     ]
    }
   ],
   "source": [
    "print(z.idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "498ca531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4707, 15026, 16102, 20355, 26947, 31606, 31645, 31719, 35236, 50474, 52116, 53646, 53788, 57782, 58900, 61756, 73053, 75472, 81102, 82197, 82974, 85952, 87984, 97589, 98691, 99735, 101126, 103636, 110651, 116355]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2ec094b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dana/anaconda3/envs/fcos/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is batch  0\n",
      "[tensor([[[[-0.2684, -0.1314,  0.2624,  ..., -0.6452, -0.7137, -0.5596],\n",
      "          [-0.3027, -0.0629,  0.0912,  ..., -0.5253, -0.5938, -0.4911],\n",
      "          [-0.2684, -0.1828, -0.1314,  ..., -0.3541, -0.4739, -0.4054],\n",
      "          ...,\n",
      "          [-0.2856, -0.2856, -0.2856,  ..., -0.2513, -0.2513, -0.0972],\n",
      "          [-0.2856, -0.2856, -0.2856,  ..., -0.2513, -0.1828, -0.0458],\n",
      "          [-0.2856, -0.2684, -0.2684,  ..., -0.2171, -0.1999, -0.1143]],\n",
      "\n",
      "         [[ 0.7129,  0.7829,  0.9930,  ...,  0.0126, -0.1099, -0.0049],\n",
      "          [ 0.6254,  0.8354,  0.8179,  ...,  0.1527,  0.0826,  0.2052],\n",
      "          [ 0.6254,  0.6604,  0.5903,  ...,  0.3452,  0.3277,  0.4503],\n",
      "          ...,\n",
      "          [ 0.6604,  0.6604,  0.6604,  ...,  0.6254,  0.6429,  0.6429],\n",
      "          [ 0.6604,  0.6604,  0.6604,  ...,  0.6254,  0.6604,  0.6954],\n",
      "          [ 0.6604,  0.6779,  0.6779,  ...,  0.6254,  0.6429,  0.6254]],\n",
      "\n",
      "         [[ 1.9603,  1.7163,  1.1934,  ...,  0.5485, -0.0964, -0.1487],\n",
      "          [ 1.8905,  1.8383,  1.1934,  ...,  0.7402,  0.2173,  0.2348],\n",
      "          [ 1.9428,  1.7860,  1.2457,  ...,  0.8971,  0.5311,  0.6356],\n",
      "          ...,\n",
      "          [ 2.0997,  2.0997,  2.0997,  ...,  2.2043,  2.1694,  2.0125],\n",
      "          [ 2.0997,  2.0997,  2.0997,  ...,  2.2043,  2.2566,  2.0648],\n",
      "          [ 2.0997,  2.1171,  2.0823,  ...,  2.2217,  2.2391,  2.0300]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5878,  0.5878,  0.5878,  ...,  0.2967,  0.2796,  0.2796],\n",
      "          [ 0.6049,  0.6049,  0.5878,  ...,  0.3994,  0.4166,  0.4508],\n",
      "          [ 0.6221,  0.6392,  0.6221,  ...,  0.4337,  0.4851,  0.5364],\n",
      "          ...,\n",
      "          [ 0.3481,  0.3652,  0.2796,  ..., -0.0629,  0.0569,  0.4337],\n",
      "          [ 0.2967,  0.2624,  0.1597,  ..., -0.1657, -0.0287,  0.0912],\n",
      "          [ 0.5022,  0.3481,  0.3138,  ..., -0.1999, -0.1486, -0.1486]],\n",
      "\n",
      "         [[ 0.7304,  0.7304,  0.7304,  ...,  0.4328,  0.4153,  0.4153],\n",
      "          [ 0.7654,  0.7654,  0.7479,  ...,  0.5378,  0.5553,  0.5903],\n",
      "          [ 0.7829,  0.8004,  0.7829,  ...,  0.5728,  0.6254,  0.6779],\n",
      "          ...,\n",
      "          [ 0.4853,  0.5028,  0.4153,  ..., -0.0049,  0.1176,  0.5028],\n",
      "          [ 0.4328,  0.3978,  0.2927,  ..., -0.1099,  0.0301,  0.1527],\n",
      "          [ 0.6429,  0.4853,  0.4503,  ..., -0.0924, -0.0399, -0.0399]],\n",
      "\n",
      "         [[ 0.9842,  0.9842,  0.9842,  ...,  0.6531,  0.6356,  0.6356],\n",
      "          [ 1.0191,  1.0191,  1.0017,  ...,  0.7576,  0.7751,  0.8099],\n",
      "          [ 1.0365,  1.0539,  1.0365,  ...,  0.7925,  0.8448,  0.8971],\n",
      "          ...,\n",
      "          [ 0.7054,  0.7228,  0.6356,  ...,  0.1999,  0.3219,  0.7054],\n",
      "          [ 0.6531,  0.6182,  0.5136,  ...,  0.0953,  0.2348,  0.3568],\n",
      "          [ 0.8622,  0.7054,  0.6705,  ...,  0.0953,  0.1476,  0.1476]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.1290,  1.9235,  ...,  2.0948,  1.9235,  1.9407],\n",
      "          [ 1.8037,  2.0777,  2.1462,  ...,  2.1975,  2.1633,  2.1119],\n",
      "          [ 1.6324,  1.5982,  1.5297,  ...,  2.1975,  2.2147,  2.2489],\n",
      "          ...,\n",
      "          [ 2.0434,  2.0434,  2.0605,  ...,  2.2318,  2.1804,  2.2318],\n",
      "          [ 2.0263,  2.0092,  2.0948,  ...,  2.2318,  2.2147,  2.2318],\n",
      "          [ 2.0434,  2.0605,  2.1462,  ...,  2.2489,  2.1633,  2.1119]],\n",
      "\n",
      "         [[ 2.2885,  2.0609,  1.8859,  ...,  2.3060,  2.1310,  2.0609],\n",
      "          [ 1.7633,  2.0259,  2.0784,  ...,  2.3410,  2.3936,  2.2535],\n",
      "          [ 1.5532,  1.4657,  1.4132,  ...,  2.3761,  2.4111,  2.4111],\n",
      "          ...,\n",
      "          [ 2.2360,  2.1485,  2.2360,  ...,  2.2185,  2.2360,  2.2185],\n",
      "          [ 2.2360,  2.2010,  2.2885,  ...,  2.2535,  2.2010,  2.1485],\n",
      "          [ 2.2710,  2.2535,  2.3410,  ...,  2.1835,  2.0084,  1.8683]],\n",
      "\n",
      "         [[ 2.2740,  2.0823,  1.8557,  ...,  2.2914,  2.0997,  2.0125],\n",
      "          [ 1.7685,  2.0823,  2.0997,  ...,  2.3437,  2.3088,  2.2391],\n",
      "          [ 1.5420,  1.5071,  1.4025,  ...,  2.4134,  2.3786,  2.3960],\n",
      "          ...,\n",
      "          [ 2.3437,  2.3088,  2.3088,  ...,  1.9428,  1.9603,  1.9428],\n",
      "          [ 2.3611,  2.3263,  2.3611,  ...,  1.9603,  1.9254,  1.8208],\n",
      "          [ 2.3611,  2.3611,  2.4483,  ...,  1.9254,  1.6465,  1.4897]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7248,  0.7077,  0.6734,  ...,  0.8104,  0.8618,  0.8961],\n",
      "          [ 0.6906,  0.6392,  0.6049,  ...,  0.8789,  0.9303,  0.9817],\n",
      "          [ 0.6734,  0.6221,  0.5878,  ...,  1.0502,  1.0844,  1.1187],\n",
      "          ...,\n",
      "          [ 1.1872,  1.2385,  1.1529,  ...,  1.2557,  1.2043,  1.1700],\n",
      "          [ 1.0159,  1.0502,  1.1358,  ...,  1.2557,  1.2899,  1.2899],\n",
      "          [ 1.0673,  1.0502,  1.0844,  ...,  1.1015,  1.1358,  1.1700]],\n",
      "\n",
      "         [[ 0.8880,  0.8529,  0.8179,  ...,  0.8880,  0.9405,  0.9755],\n",
      "          [ 0.8354,  0.7829,  0.7479,  ...,  0.9580,  1.0105,  1.0630],\n",
      "          [ 0.8179,  0.7654,  0.7304,  ...,  1.1331,  1.1681,  1.2031],\n",
      "          ...,\n",
      "          [ 1.3431,  1.3957,  1.3081,  ...,  1.4307,  1.3782,  1.3431],\n",
      "          [ 1.1681,  1.2031,  1.2906,  ...,  1.4307,  1.4657,  1.4657],\n",
      "          [ 1.2206,  1.2031,  1.2381,  ...,  1.2731,  1.3081,  1.3431]],\n",
      "\n",
      "         [[ 1.1411,  1.1062,  1.0714,  ...,  1.0888,  1.1062,  1.1411],\n",
      "          [ 1.0539,  1.0017,  0.9668,  ...,  1.1585,  1.2108,  1.2631],\n",
      "          [ 1.0365,  0.9842,  0.9494,  ...,  1.3328,  1.3677,  1.4025],\n",
      "          ...,\n",
      "          [ 1.5594,  1.6117,  1.5245,  ...,  1.7163,  1.6640,  1.6291],\n",
      "          [ 1.4200,  1.4548,  1.5420,  ...,  1.6814,  1.7163,  1.7163],\n",
      "          [ 1.4722,  1.4548,  1.4897,  ...,  1.5245,  1.5594,  1.5942]]]]), tensor([1001, 1110, 1041,  982, 1110])]\n",
      "5\n",
      "This is batch  1\n",
      "[tensor([[[[ 0.4166,  0.6392,  0.7591,  ...,  0.2111,  0.1426,  0.0056],\n",
      "          [ 0.0227,  0.2111,  0.3652,  ..., -0.2684, -0.2856, -0.2513],\n",
      "          [-0.1657, -0.0972,  0.0227,  ..., -0.6794, -0.5767, -0.4397],\n",
      "          ...,\n",
      "          [ 1.3584,  1.5468,  1.7180,  ...,  0.6906,  1.1700,  1.4783],\n",
      "          [ 1.3584,  1.4098,  1.5982,  ...,  1.5982,  1.5125,  1.4783],\n",
      "          [ 1.6153,  1.4612,  1.4098,  ...,  0.9817,  0.8276, -0.0629]],\n",
      "\n",
      "         [[ 0.5553,  0.7829,  0.8880,  ...,  0.2752,  0.2052,  0.0651],\n",
      "          [ 0.1527,  0.3452,  0.5028,  ..., -0.2150, -0.2325, -0.1975],\n",
      "          [-0.0749, -0.0049,  0.1001,  ..., -0.6352, -0.5301, -0.3901],\n",
      "          ...,\n",
      "          [ 1.8508,  2.0434,  2.2185,  ...,  0.8354,  1.3081,  1.6232],\n",
      "          [ 1.8508,  1.9034,  2.0959,  ...,  1.7458,  1.6583,  1.5882],\n",
      "          [ 2.1134,  1.9559,  1.9034,  ...,  1.1155,  0.9230,  0.0126]],\n",
      "\n",
      "         [[ 0.6356,  0.8622,  1.0191,  ...,  0.4788,  0.4091,  0.2696],\n",
      "          [ 0.1651,  0.3916,  0.5834,  ..., -0.0092, -0.0267,  0.0082],\n",
      "          [-0.0790,  0.0082,  0.1651,  ..., -0.4275, -0.3230, -0.1835],\n",
      "          ...,\n",
      "          [ 2.3611,  2.5529,  2.6400,  ...,  1.1934,  1.6291,  1.9428],\n",
      "          [ 2.3263,  2.4134,  2.6051,  ...,  2.0997,  1.9777,  1.9254],\n",
      "          [ 2.5877,  2.4308,  2.3786,  ...,  1.4722,  1.2631,  0.3568]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6221,  0.6221,  0.6221,  ..., -1.2274, -1.2788, -1.3473],\n",
      "          [ 0.6221,  0.6221,  0.6049,  ..., -1.2445, -1.2959, -1.3302],\n",
      "          [ 0.6392,  0.6221,  0.6221,  ..., -1.2274, -1.2788, -1.2788],\n",
      "          ...,\n",
      "          [-1.4843, -1.3302, -1.0219,  ..., -1.5014, -1.5870, -1.5185],\n",
      "          [-1.3473, -1.3644, -1.3302,  ..., -1.4843, -1.4672, -0.9534],\n",
      "          [-1.4158, -1.3987, -1.2959,  ..., -1.4672, -1.0904,  0.0056]],\n",
      "\n",
      "         [[ 1.3081,  1.3081,  1.3081,  ..., -1.2479, -1.2654, -1.3004],\n",
      "          [ 1.3081,  1.3081,  1.2906,  ..., -1.2654, -1.2829, -1.2829],\n",
      "          [ 1.3256,  1.3081,  1.3081,  ..., -1.2479, -1.2654, -1.2654],\n",
      "          ...,\n",
      "          [-1.2479, -1.0903, -0.7752,  ..., -1.4405, -1.4230, -1.2304],\n",
      "          [-1.2304, -1.2479, -1.2304,  ..., -1.4055, -1.3179, -0.6352],\n",
      "          [-1.3529, -1.3354, -1.2304,  ..., -1.3880, -0.9328,  0.3452]],\n",
      "\n",
      "         [[ 2.4831,  2.4831,  2.4831,  ..., -1.1247, -1.1421, -1.1596],\n",
      "          [ 2.4831,  2.4831,  2.4657,  ..., -1.1421, -1.1596, -1.1421],\n",
      "          [ 2.5006,  2.4831,  2.4831,  ..., -1.1596, -1.1421, -1.1073],\n",
      "          ...,\n",
      "          [-0.9678, -0.6367, -0.1835,  ..., -1.1247, -0.9853, -0.6193],\n",
      "          [-0.9678, -0.9330, -0.8284,  ..., -1.0724, -0.8284,  0.0082],\n",
      "          [-1.1073, -1.0898, -0.9504,  ..., -1.0550, -0.4450,  1.0191]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1119,  2.0777,  1.7694,  ..., -0.1314, -0.0116, -0.0116],\n",
      "          [ 2.1462,  1.8893,  1.1700,  ..., -0.0458, -0.1143, -0.0629],\n",
      "          [ 2.0777,  1.6324,  1.3242,  ..., -0.0801, -0.0801, -0.0458],\n",
      "          ...,\n",
      "          [-1.1589, -1.1932, -1.0390,  ..., -0.2342, -0.3198, -0.4054],\n",
      "          [-1.2274, -1.1589, -1.0562,  ..., -0.2856, -0.4226, -0.4054],\n",
      "          [-1.1932, -1.1247, -1.0904,  ..., -0.3369, -0.4397, -0.3883]],\n",
      "\n",
      "         [[ 2.3761,  2.3936,  1.9559,  ...,  0.1001,  0.2052,  0.2402],\n",
      "          [ 2.3761,  2.1485,  1.4307,  ...,  0.2052,  0.1352,  0.1877],\n",
      "          [ 2.2710,  1.8158,  1.5532,  ...,  0.2227,  0.1527,  0.1877],\n",
      "          ...,\n",
      "          [-0.8452, -0.8277, -0.6352,  ..., -0.3550, -0.3901, -0.4426],\n",
      "          [-0.9503, -0.8277, -0.6352,  ..., -0.3550, -0.3725, -0.3901],\n",
      "          [-0.9153, -0.7927, -0.6702,  ..., -0.3725, -0.4251, -0.4251]],\n",
      "\n",
      "         [[ 2.4831,  2.3437,  1.8557,  ..., -0.3055, -0.1312, -0.1312],\n",
      "          [ 2.4657,  2.2566,  1.0539,  ..., -0.1487, -0.2184, -0.1835],\n",
      "          [ 2.3786,  1.8905,  1.3328,  ..., -0.1487, -0.2184, -0.1835],\n",
      "          ...,\n",
      "          [-1.2467, -1.3513, -1.3164,  ..., -0.6367, -0.6890, -0.7587],\n",
      "          [-1.3164, -1.4036, -1.3164,  ..., -0.6890, -0.7587, -0.7238],\n",
      "          [-1.2990, -1.3164, -1.2816,  ..., -0.7238, -0.7587, -0.7413]]],\n",
      "\n",
      "\n",
      "        [[[-1.2103, -1.2959, -1.3815,  ..., -0.9363, -0.9534, -1.0219],\n",
      "          [-1.1932, -1.1760, -1.2445,  ..., -1.0390, -1.0219, -1.0219],\n",
      "          [-1.2788, -1.2103, -1.2445,  ..., -1.0219, -1.0562, -1.0904],\n",
      "          ...,\n",
      "          [-0.9192, -0.9192, -0.9363,  ..., -0.5767, -0.5424, -0.5938],\n",
      "          [-0.8849, -0.9192, -0.9192,  ..., -0.6623, -0.5596, -0.5596],\n",
      "          [-0.8678, -0.9363, -0.8849,  ..., -0.6794, -0.5767, -0.5253]],\n",
      "\n",
      "         [[-1.2654, -1.3179, -1.3529,  ..., -0.6877, -0.7052, -0.7752],\n",
      "          [-1.2479, -1.1954, -1.2129,  ..., -0.7927, -0.7752, -0.7752],\n",
      "          [-1.3004, -1.2304, -1.2129,  ..., -0.8102, -0.8102, -0.8452],\n",
      "          ...,\n",
      "          [-0.9853, -0.9853, -1.0028,  ..., -0.6001, -0.5126, -0.4776],\n",
      "          [-0.9503, -0.9853, -0.9853,  ..., -0.6352, -0.5301, -0.4426],\n",
      "          [-0.9328, -1.0028, -0.9503,  ..., -0.6702, -0.5476, -0.4076]],\n",
      "\n",
      "         [[-1.1596, -1.2293, -1.2816,  ..., -0.7238, -0.7064, -0.7761],\n",
      "          [-1.1073, -1.1073, -1.1421,  ..., -0.7936, -0.7761, -0.7761],\n",
      "          [-1.1770, -1.1073, -1.1421,  ..., -0.7936, -0.8110, -0.8110],\n",
      "          ...,\n",
      "          [-0.9330, -0.9330, -0.9504,  ..., -0.4101, -0.3578, -0.3927],\n",
      "          [-0.8981, -0.9330, -0.9678,  ..., -0.4624, -0.3753, -0.3578],\n",
      "          [-0.8807, -0.9853, -0.9330,  ..., -0.4450, -0.3927, -0.3230]]],\n",
      "\n",
      "\n",
      "        [[[-1.4329, -1.4158, -1.3987,  ..., -1.3644, -1.4158, -1.4500],\n",
      "          [-1.4672, -1.4329, -1.3987,  ..., -1.3644, -1.4158, -1.4500],\n",
      "          [-1.4500, -1.4158, -1.3644,  ..., -1.3815, -1.4158, -1.4500],\n",
      "          ...,\n",
      "          [-0.3712, -0.3712, -0.0801,  ..., -0.0629, -0.1143, -0.4568],\n",
      "          [-0.2684, -0.1999, -0.1314,  ..., -0.9877, -1.0562, -0.6623],\n",
      "          [ 0.0398,  0.0398, -0.0116,  ..., -0.6794, -0.7822, -0.6623]],\n",
      "\n",
      "         [[-1.3880, -1.3704, -1.3529,  ..., -1.3179, -1.3704, -1.4055],\n",
      "          [-1.3704, -1.3354, -1.3529,  ..., -1.3179, -1.3704, -1.4055],\n",
      "          [-1.3529, -1.3179, -1.3179,  ..., -1.3354, -1.3704, -1.4055],\n",
      "          ...,\n",
      "          [-0.2500, -0.2500,  0.0476,  ...,  0.1001,  0.0476, -0.3025],\n",
      "          [-0.1450, -0.0749, -0.0049,  ..., -0.8452, -0.9153, -0.5126],\n",
      "          [ 0.1702,  0.1702,  0.1176,  ..., -0.5301, -0.6352, -0.5126]],\n",
      "\n",
      "         [[-1.3164, -1.2990, -1.2816,  ..., -1.2467, -1.2641, -1.2990],\n",
      "          [-1.3164, -1.2816, -1.2816,  ..., -1.2467, -1.2990, -1.2990],\n",
      "          [-1.2990, -1.2641, -1.2467,  ..., -1.2641, -1.2990, -1.2990],\n",
      "          ...,\n",
      "          [ 0.0082,  0.0082,  0.3045,  ...,  0.3045,  0.2522, -0.0964],\n",
      "          [ 0.1128,  0.1825,  0.2522,  ..., -0.6367, -0.7064, -0.3055],\n",
      "          [ 0.4265,  0.4265,  0.3742,  ..., -0.3230, -0.4275, -0.3055]]]]), tensor([1087,  832, 1024,  207,  957])]\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is batch  2\n",
      "[tensor([[[[ 0.7077,  0.7248,  0.6906,  ..., -0.0629, -0.1657, -0.2513],\n",
      "          [ 0.6221,  0.4851,  0.4337,  ...,  0.0569, -0.1143, -0.2342],\n",
      "          [ 0.4337,  0.3309,  0.0912,  ...,  0.3481,  0.1768, -0.2171],\n",
      "          ...,\n",
      "          [-0.2342, -0.2513, -0.2684,  ...,  0.0227,  0.1083,  0.0912],\n",
      "          [-0.3369, -0.4054, -0.4568,  ..., -0.1486, -0.1657, -0.1143],\n",
      "          [-0.4739, -0.5938, -0.6794,  ..., -0.1657, -0.2171, -0.0972]],\n",
      "\n",
      "         [[ 0.7654,  0.7479,  0.6779,  ...,  0.7479,  0.6254,  0.5028],\n",
      "          [ 0.5553,  0.4503,  0.3978,  ...,  0.8704,  0.6954,  0.5553],\n",
      "          [ 0.2752,  0.2227,  0.0651,  ...,  1.2031,  0.9930,  0.5728],\n",
      "          ...,\n",
      "          [-0.3200, -0.3025, -0.2500,  ...,  0.8179,  0.8704,  0.9230],\n",
      "          [-0.4426, -0.4426, -0.4951,  ...,  0.7654,  0.7129,  0.7829],\n",
      "          [-0.5651, -0.5826, -0.6176,  ...,  0.7479,  0.6954,  0.8179]],\n",
      "\n",
      "         [[ 0.6531,  0.6879,  0.6356,  ...,  0.1825,  0.0256, -0.0790],\n",
      "          [ 0.5659,  0.4614,  0.4439,  ...,  0.3219,  0.0953, -0.0790],\n",
      "          [ 0.3568,  0.3916,  0.1651,  ...,  0.7228,  0.3916, -0.0964],\n",
      "          ...,\n",
      "          [-0.3055, -0.2881, -0.2707,  ...,  0.1476,  0.2871,  0.2348],\n",
      "          [-0.5147, -0.4798, -0.5321,  ...,  0.0256, -0.0092,  0.0779],\n",
      "          [-0.5495, -0.6018, -0.6541,  ..., -0.0267, -0.1138,  0.0431]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1083,  0.1768,  0.0227,  ..., -0.9020, -0.8164, -0.7137],\n",
      "          [ 0.1426,  0.2967,  0.1768,  ..., -0.7822, -0.7137, -0.4739],\n",
      "          [ 0.1254,  0.3481,  0.2111,  ..., -0.7479, -0.5767, -0.3883],\n",
      "          ...,\n",
      "          [ 0.2282,  0.1597,  0.0056,  ...,  0.1254,  0.0398,  0.0227],\n",
      "          [-0.1314, -0.3198, -0.4739,  ...,  0.1939,  0.0056, -0.0629],\n",
      "          [-0.4568, -0.6281, -0.8335,  ...,  0.2282,  0.1254, -0.0116]],\n",
      "\n",
      "         [[-0.0399,  0.0476, -0.1800,  ..., -1.2304, -1.1078, -0.9328],\n",
      "          [-0.0049,  0.1527,  0.0301,  ..., -1.0203, -0.9678, -0.6877],\n",
      "          [ 0.0301,  0.2577,  0.1176,  ..., -0.9678, -0.8277, -0.6001],\n",
      "          ...,\n",
      "          [ 0.5728,  0.4853,  0.3452,  ...,  0.2052,  0.1176,  0.1001],\n",
      "          [ 0.1877, -0.0224, -0.2150,  ...,  0.2752,  0.1352,  0.0126],\n",
      "          [-0.1625, -0.3375, -0.5826,  ...,  0.2927,  0.2052,  0.0651]],\n",
      "\n",
      "         [[-0.0964, -0.0615, -0.2010,  ..., -1.0724, -0.9853, -0.8284],\n",
      "          [-0.0615,  0.0953, -0.0267,  ..., -0.9156, -0.8284, -0.5844],\n",
      "          [-0.0441,  0.1825,  0.0605,  ..., -0.8458, -0.6890, -0.4798],\n",
      "          ...,\n",
      "          [ 0.6182,  0.5659,  0.3916,  ...,  0.3393,  0.2173,  0.1999],\n",
      "          [ 0.2696,  0.0605, -0.1835,  ...,  0.4091,  0.2173,  0.1128],\n",
      "          [-0.0790, -0.2532, -0.5495,  ...,  0.3568,  0.3045,  0.1302]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1939,  0.2624,  0.3481,  ...,  0.5878,  0.6906,  0.6906],\n",
      "          [ 0.1939,  0.1939,  0.1768,  ...,  0.6392,  0.6563,  0.7591],\n",
      "          [ 0.2967,  0.2624,  0.1597,  ...,  0.7248,  0.6392,  0.5536],\n",
      "          ...,\n",
      "          [ 0.3481,  0.3994,  0.4851,  ...,  0.3309,  0.2796,  0.3481],\n",
      "          [ 0.2453,  0.3138,  0.3652,  ...,  0.1597,  0.0398,  0.1254],\n",
      "          [ 0.1426,  0.2282,  0.2453,  ..., -0.2513, -0.3198, -0.2513]],\n",
      "\n",
      "         [[ 0.6954,  0.7654,  0.8529,  ...,  1.0980,  1.2031,  1.2556],\n",
      "          [ 0.8004,  0.7654,  0.7129,  ...,  1.1681,  1.1856,  1.2906],\n",
      "          [ 0.9930,  0.9230,  0.7654,  ...,  1.2206,  1.1331,  1.0455],\n",
      "          ...,\n",
      "          [ 0.8880,  0.9405,  1.0805,  ...,  0.9930,  0.9405,  1.0105],\n",
      "          [ 0.8179,  0.8880,  0.9405,  ...,  0.8179,  0.6954,  0.7479],\n",
      "          [ 0.7479,  0.8354,  0.8179,  ...,  0.3627,  0.2577,  0.2927]],\n",
      "\n",
      "         [[ 1.4548,  1.5245,  1.6117,  ...,  1.7860,  1.8905,  1.9254],\n",
      "          [ 1.5245,  1.5071,  1.4722,  ...,  1.8034,  1.8208,  1.9254],\n",
      "          [ 1.6465,  1.5942,  1.4548,  ...,  1.8557,  1.7685,  1.6814],\n",
      "          ...,\n",
      "          [ 1.6465,  1.6988,  1.7685,  ...,  1.6640,  1.6117,  1.6814],\n",
      "          [ 1.5594,  1.6291,  1.6814,  ...,  1.4897,  1.3328,  1.3851],\n",
      "          [ 1.4897,  1.5768,  1.5594,  ...,  1.0017,  0.9145,  0.9668]]],\n",
      "\n",
      "\n",
      "        [[[-0.8335, -0.8335, -0.8849,  ..., -0.9192, -1.1247, -0.5938],\n",
      "          [-0.8849, -0.8849, -0.6623,  ..., -0.0116, -1.2617, -0.7479],\n",
      "          [-0.9020, -0.8678, -0.3198,  ...,  1.1015, -1.1247, -0.9192],\n",
      "          ...,\n",
      "          [-0.4739, -0.6794, -0.6623,  ..., -0.4568, -0.5424, -0.9363],\n",
      "          [-0.6965, -0.7479, -0.7137,  ..., -0.6109, -0.5596, -0.5938],\n",
      "          [-0.7993, -0.7822, -0.7479,  ..., -0.5938, -0.6452, -0.6281]],\n",
      "\n",
      "         [[-0.2500, -0.3025, -0.3901,  ..., -0.6877, -1.0203, -0.6527],\n",
      "          [-0.2850, -0.3550, -0.1800,  ...,  0.2402, -1.1604, -0.7752],\n",
      "          [-0.2675, -0.2675,  0.2227,  ...,  1.3431, -1.0203, -0.9153],\n",
      "          ...,\n",
      "          [ 0.0126, -0.2325, -0.2500,  ..., -0.1450, -0.2150, -0.5126],\n",
      "          [-0.1275, -0.1975, -0.1975,  ..., -0.1275, -0.1275, -0.1975],\n",
      "          [-0.2150, -0.2325, -0.2150,  ..., -0.1975, -0.1975, -0.1625]],\n",
      "\n",
      "         [[-1.4384, -1.4384, -1.4210,  ..., -0.6018, -0.9678, -0.5844],\n",
      "          [-1.5256, -1.4559, -1.0898,  ...,  0.3393, -1.1073, -0.7413],\n",
      "          [-1.5430, -1.3513, -0.6018,  ...,  1.4548, -0.9330, -0.8981],\n",
      "          ...,\n",
      "          [-1.1421, -1.3861, -1.4210,  ..., -1.0724, -1.1073, -1.3687],\n",
      "          [-1.4210, -1.4210, -1.3687,  ..., -1.2467, -1.2293, -1.2467],\n",
      "          [-1.4036, -1.4559, -1.4907,  ..., -1.1073, -1.0898, -1.0027]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5982,  1.1700,  0.6392,  ...,  1.5982,  1.6838,  1.5297],\n",
      "          [ 1.4269,  1.2385,  1.2214,  ...,  1.7865,  1.7352,  1.4098],\n",
      "          [ 1.1700,  0.8961,  1.3413,  ...,  1.6324,  1.5125,  1.6838],\n",
      "          ...,\n",
      "          [ 1.5639,  1.5125,  1.4098,  ...,  0.7591,  0.6563,  0.6563],\n",
      "          [ 0.7248,  1.0331,  1.4269,  ...,  0.6734,  0.5193,  0.4508],\n",
      "          [ 0.6049,  0.5364,  0.6049,  ...,  0.6906,  0.5022,  0.4679]],\n",
      "\n",
      "         [[ 1.6933,  1.2556,  0.6604,  ...,  1.6758,  1.6933,  1.5882],\n",
      "          [ 1.5182,  1.3256,  1.2206,  ...,  1.8683,  1.7808,  1.4832],\n",
      "          [ 1.1506,  0.9055,  1.3957,  ...,  1.7108,  1.5882,  1.7283],\n",
      "          ...,\n",
      "          [ 1.3431,  1.3431,  1.2381,  ...,  0.3978,  0.3102,  0.3102],\n",
      "          [ 0.4153,  0.8004,  1.2556,  ...,  0.3277,  0.1702,  0.1176],\n",
      "          [ 0.2927,  0.2227,  0.3277,  ...,  0.3102,  0.1176,  0.1176]],\n",
      "\n",
      "         [[ 1.6988,  1.2631,  0.7054,  ...,  1.2282,  1.3677,  1.2457],\n",
      "          [ 1.5420,  1.3502,  1.3154,  ...,  1.5245,  1.5071,  1.1759],\n",
      "          [ 1.2108,  0.9319,  1.4025,  ...,  1.4025,  1.2980,  1.4374],\n",
      "          ...,\n",
      "          [ 1.3154,  1.2980,  1.1585,  ...,  0.4788,  0.3393,  0.3393],\n",
      "          [ 0.4091,  0.7751,  1.1759,  ...,  0.3045,  0.1825,  0.1476],\n",
      "          [ 0.2522,  0.2173,  0.3742,  ...,  0.3393,  0.1476,  0.1476]]]]), tensor([ 995,  982, 1107, 1001,  559])]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(dl):\n",
    "    if i<3:\n",
    "        print(\"This is batch \",i)\n",
    "        print(x)\n",
    "        print(len(x[1]))\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c539b011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.2684, -0.1314,  0.2624,  ..., -0.6452, -0.7137, -0.5596],\n",
      "         [-0.3027, -0.0629,  0.0912,  ..., -0.5253, -0.5938, -0.4911],\n",
      "         [-0.2684, -0.1828, -0.1314,  ..., -0.3541, -0.4739, -0.4054],\n",
      "         ...,\n",
      "         [-0.2856, -0.2856, -0.2856,  ..., -0.2513, -0.2513, -0.0972],\n",
      "         [-0.2856, -0.2856, -0.2856,  ..., -0.2513, -0.1828, -0.0458],\n",
      "         [-0.2856, -0.2684, -0.2684,  ..., -0.2171, -0.1999, -0.1143]],\n",
      "\n",
      "        [[ 0.7129,  0.7829,  0.9930,  ...,  0.0126, -0.1099, -0.0049],\n",
      "         [ 0.6254,  0.8354,  0.8179,  ...,  0.1527,  0.0826,  0.2052],\n",
      "         [ 0.6254,  0.6604,  0.5903,  ...,  0.3452,  0.3277,  0.4503],\n",
      "         ...,\n",
      "         [ 0.6604,  0.6604,  0.6604,  ...,  0.6254,  0.6429,  0.6429],\n",
      "         [ 0.6604,  0.6604,  0.6604,  ...,  0.6254,  0.6604,  0.6954],\n",
      "         [ 0.6604,  0.6779,  0.6779,  ...,  0.6254,  0.6429,  0.6254]],\n",
      "\n",
      "        [[ 1.9603,  1.7163,  1.1934,  ...,  0.5485, -0.0964, -0.1487],\n",
      "         [ 1.8905,  1.8383,  1.1934,  ...,  0.7402,  0.2173,  0.2348],\n",
      "         [ 1.9428,  1.7860,  1.2457,  ...,  0.8971,  0.5311,  0.6356],\n",
      "         ...,\n",
      "         [ 2.0997,  2.0997,  2.0997,  ...,  2.2043,  2.1694,  2.0125],\n",
      "         [ 2.0997,  2.0997,  2.0997,  ...,  2.2043,  2.2566,  2.0648],\n",
      "         [ 2.0997,  2.1171,  2.0823,  ...,  2.2217,  2.2391,  2.0300]]]), 1001)\n"
     ]
    }
   ],
   "source": [
    "print(trainset[4707])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2f9974f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "889dcecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a462235b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9275\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a930faf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(trainset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "682cecac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    read_csv('dd')\n",
    "except:\n",
    "    print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "38ac9090",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = INaturalist(root = '/MD1400/jinkyu/test2017',csv_path = '/MD1400/jinkyu/inaturalist-user-120k/test.csv',version = '2017', download = False, transform = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5fa29bc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'e266241cfaf647e67b02af066df3e13e'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18446/2799877959.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_18446/2585468214.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mthis_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_csv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthis_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'e266241cfaf647e67b02af066df3e13e'"
     ]
    }
   ],
   "source": [
    "testset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ec139dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182707\n"
     ]
    }
   ],
   "source": [
    "print(len((testset.image_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "77b5ddd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675170\n"
     ]
    }
   ],
   "source": [
    "print(len((trainset.image_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "46157c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OrderedDict([('image_id', 'c328b4e68bab48659f5627e9e1aa430d'), ('class', '388'), ('label', '11901')]), OrderedDict([('image_id', 'e266241cfaf647e67b02af066df3e13e'), ('class', '209'), ('label', '47188')]), OrderedDict([('image_id', 'e0adcc71c0542bc912c2d380e8dd759f'), ('class', '703'), ('label', '49651')]), OrderedDict([('image_id', 'e49ae0faae685701d9509c6d7d3dd14a'), ('class', '149'), ('label', '55851')]), OrderedDict([('image_id', '25b6401f8db3ae8696da29bc45dc3529'), ('class', '922'), ('label', '11867')]), OrderedDict([('image_id', '7ab01c6ebd426727bd68baf3097a84c9'), ('class', '896'), ('label', '49882')]), OrderedDict([('image_id', '6989f90b44760ece405b6bca69f779b3'), ('class', '1187'), ('label', '5112')]), OrderedDict([('image_id', '1317028067092050235e53e8cc053192'), ('class', '825'), ('label', '55990')]), OrderedDict([('image_id', '90a774bc5229cbbfdef974722ea32d8a'), ('class', '974'), ('label', '52136')]), OrderedDict([('image_id', '0f3a106eb2565836a5e9cd9ffa367767'), ('class', '828'), ('label', '52576')])]\n"
     ]
    }
   ],
   "source": [
    "print(testset.split_csv[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2f32b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ???? root를 test가 아니라 train_val_images에서 찾아야 하네 testset도 ㅋㅋㅋ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1f547cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = INaturalist(root = '/MD1400/jinkyu/train_val_images',csv_path = '/MD1400/jinkyu/inaturalist-user-120k/test.csv',version = '2017', download = False, transform = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "14133959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.7583, -1.7240, -1.6898,  ...,  1.9749,  1.6153,  1.2899],\n",
       "          [-1.7240, -1.7240, -1.7069,  ...,  1.4440,  0.9817,  1.2043],\n",
       "          [-1.7583, -1.7754, -1.7754,  ...,  1.1700,  1.0502,  1.5468],\n",
       "          ...,\n",
       "          [ 1.4440,  1.6324,  1.8893,  ...,  1.5125,  2.1633,  1.5468],\n",
       "          [ 1.3242,  1.4612,  1.7523,  ...,  2.2147,  1.7865,  1.6667],\n",
       "          [ 1.3070,  1.3755,  1.6324,  ...,  2.2147,  2.0092,  1.9407]],\n",
       " \n",
       "         [[-1.6856, -1.6506, -1.6155,  ...,  1.8158,  1.2556,  0.8004],\n",
       "          [-1.6506, -1.6506, -1.6331,  ...,  1.3256,  0.5903,  0.6254],\n",
       "          [-1.6331, -1.6506, -1.6506,  ...,  0.9405,  0.5203,  0.8529],\n",
       "          ...,\n",
       "          [ 0.5378,  0.7829,  1.1155,  ...,  1.3256,  1.8508,  0.9930],\n",
       "          [ 0.5028,  0.6779,  1.0105,  ...,  2.2360,  1.7458,  1.5007],\n",
       "          [ 0.5553,  0.6254,  0.8704,  ...,  2.2535,  2.1660,  2.0784]],\n",
       " \n",
       "         [[-1.5256, -1.4907, -1.4559,  ...,  1.0191,  0.6008,  0.2348],\n",
       "          [-1.4907, -1.4907, -1.4733,  ...,  0.5136, -0.0092,  0.1128],\n",
       "          [-1.4907, -1.5081, -1.5081,  ...,  0.3045, -0.0092,  0.3742],\n",
       "          ...,\n",
       "          [-0.0615,  0.1999,  0.5311,  ...,  0.6705,  1.1934,  0.2696],\n",
       "          [-0.0964,  0.0779,  0.4091,  ...,  1.6988,  1.2631,  0.9842],\n",
       "          [-0.0615,  0.0256,  0.3219,  ...,  1.8383,  1.8905,  1.8905]]]),\n",
       " 209)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "024136f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dana/anaconda3/envs/fcos/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([5, 3, 224, 224])\n",
      "1\n",
      "torch.Size([5, 3, 224, 224])\n",
      "2\n",
      "torch.Size([5, 3, 224, 224])\n",
      "3\n",
      "torch.Size([5, 3, 224, 224])\n",
      "4\n",
      "torch.Size([5, 3, 224, 224])\n",
      "5\n",
      "torch.Size([5, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dl, 0): \n",
    "    print(i)\n",
    "    print(data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1393f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
